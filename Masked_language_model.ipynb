{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-cri-spy/SLM/blob/main/Masked_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2vZXo1v_zfD",
        "outputId": "0d7baab8-e7e9-4e5e-de01-a1b203e54dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "Model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(Model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(Model_name)\n",
        "mask = tokenizer.mask_token\n",
        "sentence = f\"i want to {mask} pizza for tonight\"\n",
        "tokens = tokenizer.tokenize(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8EcLRRpFB8U",
        "outputId": "5bbf345c-9517-4757-81fc-815d3c9b8126"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'want', 'to', '[MASK]', 'pizza', 'for', 'tonight']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoaded_inputs = tokenizer(sentence, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "xUFA9kvwFCph"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**encoaded_inputs)"
      ],
      "metadata": {
        "id": "5E2r_IcTFZm-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs.logits.detach().numpy()[0]\n",
        "logits.shape\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eynjvas0FjVY",
        "outputId": "fde7f5ed-40a4-4388-b0bc-0c0d92999b6b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ -7.5025334  -7.3913217  -7.586538  ...  -6.3825173  -6.0440683\n",
            "   -6.493639 ]\n",
            " [ -7.6965303  -7.9414086  -7.721745  ...  -6.4760494  -6.0735264\n",
            "   -6.71274  ]\n",
            " [-12.971294  -12.487409  -12.742433  ...  -9.13309    -7.898856\n",
            "   -8.671511 ]\n",
            " ...\n",
            " [ -9.776632   -9.4683     -9.461386  ...  -8.690693   -5.772199\n",
            "   -8.887491 ]\n",
            " [ -8.944189   -9.032674   -8.518424  ...  -6.773488   -6.3178782\n",
            "   -7.1574054]\n",
            " [-14.260288  -14.460198  -14.9671755 ... -11.888977  -11.722957\n",
            "  -13.036328 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_logits= logits[tokens.index(mask)+1]\n"
      ],
      "metadata": {
        "id": "ivRTevYTGF5M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_scores = softmax(mask_logits)"
      ],
      "metadata": {
        "id": "NeQnQFSOHNl2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.argsort(confidence_scores)[::-1][:5]:\n",
        "  pred_token = tokenizer.decode(i)\n",
        "  score = confidence_scores\n",
        "  #print(pred_token, confidence_scores[i])\n",
        "\n",
        "  print(sentence.replace(mask,pred_token),score )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NY7L7RRHt1u",
        "outputId": "25f0abf0-af3b-4b79-d4f1-de606c0c767f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i want to have pizza for tonight [2.3385635e-10 3.2347267e-10 4.7491072e-10 ... 8.0100276e-10 4.7084865e-09\n",
            " 1.2558663e-09]\n",
            "i want to get pizza for tonight [2.3385635e-10 3.2347267e-10 4.7491072e-10 ... 8.0100276e-10 4.7084865e-09\n",
            " 1.2558663e-09]\n",
            "i want to eat pizza for tonight [2.3385635e-10 3.2347267e-10 4.7491072e-10 ... 8.0100276e-10 4.7084865e-09\n",
            " 1.2558663e-09]\n",
            "i want to grab pizza for tonight [2.3385635e-10 3.2347267e-10 4.7491072e-10 ... 8.0100276e-10 4.7084865e-09\n",
            " 1.2558663e-09]\n",
            "i want to make pizza for tonight [2.3385635e-10 3.2347267e-10 4.7491072e-10 ... 8.0100276e-10 4.7084865e-09\n",
            " 1.2558663e-09]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is how module undrustand the language"
      ],
      "metadata": {
        "id": "QYgwv7tBJSeQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPWZ+VsUrsbTnqRdxl3cPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
