

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1u+mXVRqa8cwfLdDOKGXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-cri-spy/SLM/blob/main/Bert01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bert Question Answering This notebook explores using the BERT (Bidirectional Encoder Representations from Transformers) model for answering questions posed against a context. It is an engaging way to understand how natural language understanding works in practice."
      ],
      "metadata": {
        "id": "jcIHgLzxAe9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install datasets\n",
        "!pip install plotly"
      ],
      "metadata": {
        "id": "Pwmh0CRkBioa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e7d7d1-65aa-4b32-f7df-70b775aa74c5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.10.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.1.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1->transformers[torch]) (3.0.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import(\n",
        "    BertForQuestionAnswering,\n",
        "    BertTokenizerFast,\n",
        "\n",
        ")\n",
        "from scipy.special import softmax\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qpuVHIGWA-aR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation : - defining the context and quastion that will be used to demonstate the bert models q/a capabilities"
      ],
      "metadata": {
        "id": "QY7Vq-rEDknq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"The giraffe is a large African hoofed mammal belonging to the genus Giraffa. It is the tallest living terrestrial animal and the largest ruminant on Earth. Traditionally, giraffes were thought to be one species, Giraffa camelopardalis, with nine subspecies. Most recently, researchers proposed dividing them into up to eight extant species due to new research into their mitochondrial and nuclear DNA, as well as morphological measurements. Seven other extinct species of Giraffa are known from the fossil record.\"\n",
        "question = \"How many giraffe species are there?\""
      ],
      "metadata": {
        "id": "aqsWK4-FDPGd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Setup :- loading the bert model and tokenizer designed for q/a task"
      ],
      "metadata": {
        "id": "sB-vvck_EKtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepset/bert-base-cased-squad2\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "model = BertForQuestionAnswering.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpEoRSV9ED4D",
        "outputId": "90952059-63f5-4a84-f420-3003875229ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question Answering\n",
        "Tokenize the context and the question, and perform inference to get model predictions."
      ],
      "metadata": {
        "id": "y6I4Gf9CFWyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(question , context , return_tensors = \"pt\")\n",
        "tokenizer.tokenize(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s38WMI1vFlFX",
        "outputId": "3404c383-d443-4ef6-efd7-36f244067d22"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'g',\n",
              " '##ira',\n",
              " '##ffe',\n",
              " 'is',\n",
              " 'a',\n",
              " 'large',\n",
              " 'African',\n",
              " 'ho',\n",
              " '##of',\n",
              " '##ed',\n",
              " 'ma',\n",
              " '##mmal',\n",
              " 'belonging',\n",
              " 'to',\n",
              " 'the',\n",
              " 'genus',\n",
              " 'G',\n",
              " '##ira',\n",
              " '##ff',\n",
              " '##a',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'the',\n",
              " 'tallest',\n",
              " 'living',\n",
              " 'terrestrial',\n",
              " 'animal',\n",
              " 'and',\n",
              " 'the',\n",
              " 'largest',\n",
              " 'r',\n",
              " '##umi',\n",
              " '##nant',\n",
              " 'on',\n",
              " 'Earth',\n",
              " '.',\n",
              " 'Traditionally',\n",
              " ',',\n",
              " 'g',\n",
              " '##ira',\n",
              " '##ffe',\n",
              " '##s',\n",
              " 'were',\n",
              " 'thought',\n",
              " 'to',\n",
              " 'be',\n",
              " 'one',\n",
              " 'species',\n",
              " ',',\n",
              " 'G',\n",
              " '##ira',\n",
              " '##ff',\n",
              " '##a',\n",
              " 'came',\n",
              " '##lop',\n",
              " '##ard',\n",
              " '##alis',\n",
              " ',',\n",
              " 'with',\n",
              " 'nine',\n",
              " 'subspecies',\n",
              " '.',\n",
              " 'Most',\n",
              " 'recently',\n",
              " ',',\n",
              " 'researchers',\n",
              " 'proposed',\n",
              " 'dividing',\n",
              " 'them',\n",
              " 'into',\n",
              " 'up',\n",
              " 'to',\n",
              " 'eight',\n",
              " 'extant',\n",
              " 'species',\n",
              " 'due',\n",
              " 'to',\n",
              " 'new',\n",
              " 'research',\n",
              " 'into',\n",
              " 'their',\n",
              " 'mitochondrial',\n",
              " 'and',\n",
              " 'nuclear',\n",
              " 'DNA',\n",
              " ',',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'm',\n",
              " '##or',\n",
              " '##phological',\n",
              " 'measurements',\n",
              " '.',\n",
              " 'Seven',\n",
              " 'other',\n",
              " 'extinct',\n",
              " 'species',\n",
              " 'of',\n",
              " 'G',\n",
              " '##ira',\n",
              " '##ff',\n",
              " '##a',\n",
              " 'are',\n",
              " 'known',\n",
              " 'from',\n",
              " 'the',\n",
              " 'fossil',\n",
              " 'record',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the model and getting the start and end scores"
      ],
      "metadata": {
        "id": "PIHsRPY-GUP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "start_scores , end_scores = softmax(outputs.start_logits)[0], softmax(outputs.end_logits)[0]\n"
      ],
      "metadata": {
        "id": "pPPdnXEiF7LS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of token scores\n",
        "plot the scores associated with each token to undrustand the model's decision-making process"
      ],
      "metadata": {
        "id": "XaPHL8IWIAQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataframe with the score and plotting them\n",
        "\n",
        "scores_df = pd.DataFrame({\n",
        "    \"Token Position\": list(range(len(start_scores))) * 2 ,\n",
        "    \"score\": list(start_scores) + list(end_scores) ,\n",
        "    \"score type\": [\"Start\"] * len(start_scores) + [\"End\"] * len(end_scores),\n",
        "\n",
        "})\n",
        "\n",
        "px.bar(scores_df , x = \"Token Position\" , y= \"score\", color = \"score type\" , barmode = \"group\", title = \"Start and end Scores for Tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "yzFZmKXpHx81",
        "outputId": "66f7c449-93f4-41ac-b0f3-3b932a6fb25e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9fb7909a-d61d-4ada-b7a8-7651cf56d3f5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9fb7909a-d61d-4ada-b7a8-7651cf56d3f5\")) {                    Plotly.newPlot(                        \"9fb7909a-d61d-4ada-b7a8-7651cf56d3f5\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"score type=Start\\u003cbr\\u003eToken Position=%{x}\\u003cbr\\u003escore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Start\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Start\",\"offsetgroup\":\"Start\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123],\"xaxis\":\"x\",\"y\":[0.110562995,0.00011341327,0.000062823,0.00014711425,0.000053150965,0.00003934378,0.000032453067,0.000063790896,0.00007104183,0.00008052275,0.000039239458,0.00007679666,0.00328637,0.00007159738,0.00035968548,0.00006388581,0.0003527255,0.0009797268,0.00016720349,0.0003562335,0.00006524893,0.000031029187,0.000269017,0.00014463744,0.00007680443,0.00004432611,0.00006291377,0.000090585374,0.00026758327,0.00005121657,0.00011107912,0.000034898836,0.000067357345,0.0005159952,0.00008296306,0.0001597134,0.0007330456,0.00008748685,0.00018872214,0.000047467256,0.00004317152,0.00010178204,0.00023131377,0.00015378364,0.00005088687,0.000021036143,0.00003764291,0.00010657027,0.000051953313,0.00017722667,0.00009973043,0.016736183,0.000104643645,0.00015263971,0.00007070833,0.0000783224,0.00020973878,0.00009362992,0.00008382101,0.03040783,0.00047557557,0.000027916218,0.002607718,0.00010992841,0.00034139614,0.000059910853,0.0007819377,0.00005589714,0.00006741261,0.00001771262,0.000031099993,0.00014674781,0.0551518,0.0011989155,0.0006257977,0.0005373882,0.00010498791,0.00005424468,0.00017647498,0.00012876336,0.00017141315,0.00025467385,0.0002979555,0.1354282,0.00036844495,0.6243406,0.00093274144,0.001706739,0.00013230165,0.00003782608,0.00009115933,0.00009047046,0.000042292082,0.000051434003,0.00046873884,0.000033361346,0.00010841752,0.000059128513,0.000017892058,0.000035805708,0.00002807095,0.000029785691,0.00006692463,0.00004026965,0.000026400312,0.000049994327,0.000029507288,0.0011947935,0.00003315474,0.00005827402,0.00003381592,0.000034496497,0.0012869107,0.000055937457,0.00014580076,0.000016476382,0.000054080007,0.000050528386,0.000053787295,0.000053560278,0.00006581847,0.00002679719,0.000029655594,0.000039239312],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"score type=End\\u003cbr\\u003eToken Position=%{x}\\u003cbr\\u003escore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"End\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"End\",\"offsetgroup\":\"End\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123],\"xaxis\":\"x\",\"y\":[0.12044649,0.000053372558,0.00009372519,0.000022573086,0.000042293468,0.00008724692,0.00011216902,0.00004681719,0.000056314293,0.000064784115,0.00006836774,0.000047168185,0.00006392442,0.000044742428,0.00022932472,0.00005563126,0.000054606997,0.00013460654,0.00011029675,0.000055986897,0.00010120839,0.00008717755,0.00004583904,0.0006491053,0.000043529762,0.000050836155,0.000041277977,0.00006061981,0.000072284034,0.00004833208,0.00016950154,0.00084977504,0.00039260255,0.000058448924,0.000042139112,0.000031634198,0.0005709305,0.00008583745,0.00017055127,0.00020155756,0.000054224325,0.00002683234,0.00013715817,0.00003357483,0.000039850343,0.00018596849,0.000058752943,0.0009036107,0.00033061233,0.000036696176,0.00004964017,0.00006395331,0.000035805515,0.000066283625,0.00018198008,0.000035435518,0.00002029197,0.000028624123,0.000038299215,0.014456838,0.012261555,0.00015811385,0.0002036565,0.000047727553,0.00028308373,0.00083138415,0.00007243993,0.000052415464,0.0001006079,0.00046675155,0.0003856465,0.000027607366,0.037072245,0.011199101,0.020960163,0.00003601469,0.00006509762,0.000050021197,0.000033700966,0.00003048766,0.000026510126,0.00029230956,0.000050846338,0.004290373,0.00015739998,0.63891876,0.0026353563,0.123222336,0.000069322625,0.00004701809,0.00002830462,0.00006390637,0.0000442963,0.00003673854,0.00014078166,0.00005353017,0.00005726028,0.00018836798,0.00014205235,0.00005048405,0.00006211184,0.000055307934,0.00003798668,0.00004967161,0.000075187236,0.00024280725,0.000106689804,0.0005724901,0.00006642411,0.00006390101,0.00009535725,0.00006617903,0.000052954587,0.000047731017,0.00022504387,0.00033447717,0.000043994016,0.00005984744,0.0000385862,0.000041582447,0.000058584974,0.0001227313,0.000110218316,0.000068368005],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Token Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"score\"}},\"legend\":{\"title\":{\"text\":\"score type\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Start and end Scores for Tokens\"},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9fb7909a-d61d-4ada-b7a8-7651cf56d3f5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dadf16e7"
      },
      "source": [
        "Extracting the Answer\n",
        "Identify the tokens that comprise the answer based on the highest start and end scores."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the answer from the model\n",
        "start_idx = np.argmax(start_scores)\n",
        "end_idx = np.argmax(end_scores)\n",
        "answer_ids = inputs.input_ids[0][start_idx: end_idx + 1]\n",
        "answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids)\n",
        "answer = tokenizer.convert_tokens_to_string(answer_tokens)\n"
      ],
      "metadata": {
        "id": "sFp2cvKELHS3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Usage: Sliding Windows & Stride for QA\n",
        "Define a function to automate the question answering process with new contexts and questions."
      ],
      "metadata": {
        "id": "Vd5pScCgLTlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2\n",
        "# Defining a function to predict the answer to a question given a context\n",
        "def predict_answer(context, question):\n",
        "    inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    start_scores, end_scores = softmax(outputs.start_logits)[0], softmax(outputs.end_logits)[0]\n",
        "    start_idx = np.argmax(start_scores)\n",
        "    end_idx = np.argmax(end_scores)\n",
        "    confidence_score = (start_scores[start_idx] + end_scores[end_idx]) /2\n",
        "    answer_ids = inputs.input_ids[0][start_idx: end_idx + 1]\n",
        "    answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids)\n",
        "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "    if answer != tokenizer.cls_token:\n",
        "        return answer, confidence_score\n",
        "    return None, confidence_score"
      ],
      "metadata": {
        "id": "Oj4mYOC4LNGg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the Function\n",
        "Test the predict answer function with various questions and contexts."
      ],
      "metadata": {
        "id": "znVJeo3fLhIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a new context and predicting answers to some questions\n",
        "context = \"\"\"Coffee is a beverage brewed from roasted coffee beans. Darkly colored, bitter, and slightly acidic, coffee has a stimulating effect on humans, primarily due to its caffeine content. It has the highest sales in the world market for hot drinks.[2]\n",
        "\n",
        "The seeds of the Coffea plant's fruits are separated to produce unroasted green coffee beans. The beans are roasted and then ground into fine particles typically steeped in hot water before being filtered out, producing a cup of coffee. It is usually served hot, although chilled or iced coffee is common. Coffee can be prepared and presented in a variety of ways (e.g., espresso, French press, caffè latte, or already-brewed canned coffee). Sugar, sugar substitutes, milk, and cream are often added to mask the bitter taste or enhance the flavor.\n",
        "\n",
        "Though coffee is now a global commodity, it has a long history tied closely to food traditions around the Red Sea. The earliest credible evidence of coffee drinking as the modern beverage appears in modern-day Yemen in southern Arabia in the middle of the 15th century in Sufi shrines, where coffee seeds were first roasted and brewed in a manner similar to how it is now prepared for drinking.[3] The coffee beans were procured by the Yemenis from the Ethiopian Highlands via coastal Somali intermediaries, and cultivated in Yemen. By the 16th century, the drink had reached the rest of the Middle East and North Africa, later spreading to Europe.\n",
        "\n",
        "The two most commonly grown coffee bean types are C. arabica and C. robusta.[4] Coffee plants are cultivated in over 70 countries, primarily in the equatorial regions of the Americas, Southeast Asia, the Indian subcontinent, and Africa. As of 2023, Brazil was the leading grower of coffee beans, producing 35% of the world's total. Green, unroasted coffee is traded as an agricultural commodity. Despite sales of coffee reaching billions of dollars worldwide, farmers producing coffee beans disproportionately live in poverty. Critics of the coffee industry have also pointed to its negative impact on the environment and the clearing of land for coffee-growing and water use. The global coffee industry is massive and worth $495.50 billion as of 2023.[5] Brazil, Vietnam, and Colombia are the top exporters of coffee beans as of 2023. \\n Rapid growth in coffee production in South America during the second half of the 19th century was matched by an increase in consumption in developed countries, though nowhere has this growth been as pronounced as in the United States, where a high rate of population growth was compounded by doubling of per capita consumption between 1860 and 1920. Though the United States was not the heaviest coffee-drinking nation at the time (Belgium, the Netherlands and Nordic countries all had comparable or higher levels of per capita consumption), due to its sheer size, it was already the largest consumer of coffee in the world by 1860, and, by 1920, around half of all coffee produced worldwide was consumed in the US.[37]\n",
        "\n",
        "Coffee has become a vital cash crop for many developing countries. Over one hundred million people in developing countries have become dependent on coffee as their primary source of income. It has become the primary export and economic backbone for African countries like Uganda, Burundi, Rwanda, and Ethiopia,[40] as well as many Central American countries.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "len(tokenizer.tokenize(context))\n",
        "predict_answer(context, \"What is coffee?\")\n",
        "predict_answer(context, \"What are the most common coffee beans?\")\n",
        "predict_answer(context, \"How can I make ice coffee?\")\n",
        "predict_answer(context[4000:], \"How many people are dependent on coffee for their income?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aji0gZ7ALbic",
        "outputId": "2fbd6523-049f-49ea-db0b-ea461f0c762a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, np.float32(0.99884295))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to chunk sentences\n",
        "def chunk_sentences(sentences, chunk_size, stride):\n",
        "    chunks = []\n",
        "    num_sentences = len(sentences)\n",
        "    for i in range(0, num_sentences, chunk_size - stride):\n",
        "        chunk = sentences[i: i + chunk_size]\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "Ut7NNaq9LuAD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Sentence 1.\",\n",
        "    \"Sentence 2.\",\n",
        "    \"Sentence 3.\",\n",
        "    \"Sentence 4.\",\n",
        "    \"Sentence 5.\",\n",
        "    \"Sentence 6.\",\n",
        "    \"Sentence 7.\",\n",
        "    \"Sentence 8.\",\n",
        "    \"Sentence 9.\",\n",
        "    \"Sentence 10.\"\n",
        "]\n",
        "\n",
        "\n",
        "sentences = context.split(\"\\n\")\n",
        "chunked_sentences = chunk_sentences(sentences, chunk_size=3, stride=1)\n",
        "\n",
        "\n",
        "questions = [\"What is coffee?\", \"What are the most common coffee beans?\", \"How can I make ice coffee?\", \"How many people are dependent on coffee for their income?\"]\n",
        "\n",
        "answers = {}\n",
        "\n",
        "for chunk in chunked_sentences:\n",
        "    sub_context = \"\\n\".join(chunk)\n",
        "    for question in questions:\n",
        "        answer, score = predict_answer(sub_context, question)\n",
        "\n",
        "        if answer:\n",
        "            if question not in answers:\n",
        "                answers[question] = (answer, score)\n",
        "            else:\n",
        "                if score > answers[question][1]:\n",
        "                    answers[question] = (answer, score)\n",
        "\n",
        "print(answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhhwmfhULuzL",
        "outputId": "21f54364-2213-45bc-83e6-57b172362686"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'What is coffee?': ('a beverage brewed from roasted coffee beans', np.float32(0.9282471)), 'What are the most common coffee beans?': ('C. arabica and C. robusta', np.float32(0.948103)), 'How many people are dependent on coffee for their income?': ('Over one hundred million', np.float32(0.8877787))}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sai_vihaar = \"\"\"\n",
        "Sai Vihaar Inn and Suites is a budget-friendly hotel located in Mysuru, Karnataka. It offers clean and comfortable rooms\n",
        "close to major attractions like Mysore Zoo and Mysore Palace. The hotel is located at 849 N26/2, Zoo Road, Nazarbad,\n",
        "Ittige Gudu, Mysuru, Karnataka 570010. The available room types include Queen, King, Suite, and Quadruple rooms with\n",
        "both AC and non-AC options. Prices per night range from ₹2200 to ₹2500. Check-in time is from 2:00 PM to 11:00 PM,\n",
        "and check-out is by 12:00 PM. Guests enjoy free Wi-Fi, free private parking, 24-hour room service, and an in-house\n",
        "vegetarian restaurant. Pets are not allowed. The hotel also provides laundry service, car hire, currency exchange,\n",
        "and security with CCTV. It is about 1.6 km from Mysore Palace and just 300 meters from Mysore Zoo. The hotel is\n",
        "known for its prime location, courteous staff, and clean rooms.\n",
        "\"\"\"\n",
        "\n",
        "len(tokenizer.tokenize(Sai_vihaar))\n",
        "predict_answer(Sai_vihaar, \"What is Sai Vihaar Inn?\")\n",
        "predict_answer(Sai_vihaar, \"wher it is located?\")\n",
        "predict_answer(Sai_vihaar, \"what types of room available?\")\n",
        "predict_answer(Sai_vihaar[4000:], \"how far from mysore palace?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEI27VPEMoaX",
        "outputId": "c9ef8a49-028e-4e6c-ca7d-f867e9f0a4fa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, np.float32(0.9940071))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_answer(Sai_vihaar,\"can you pls tell me about sai vihaar inn and suites?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfyQSS2gNHf9",
        "outputId": "48980bfa-6cc6-4579-f2cb-19a732bc7e4e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, np.float32(0.34804034))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}
