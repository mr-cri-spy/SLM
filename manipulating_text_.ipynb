{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTQgQ7TGbN2xwy+CNoXF3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-cri-spy/SLM/blob/main/manipulating_text_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pQs3Qa9DHsRh"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY=\"use api\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "e2dQYzSFI5s9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ab79118"
      },
      "source": [
        "To use the Google Generative AI API, you'll need an API key. It looks like you already have one set up in a variable `GOOGLE_API_KEY`. You can use that directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dea69c8"
      },
      "source": [
        "Before you can make any API calls, you need to initialize the Generative Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b60b401"
      },
      "source": [
        "# Initialize the Gemini API\n",
        "# Using gemini-1.5-flash as it's a good model for code generation\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "gemini_model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cb47915"
      },
      "source": [
        "Now you can make API calls to generate code. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "f1b245f4",
        "outputId": "1d6c44a0-f914-4c45-ab56-2e2d52a90d5f"
      },
      "source": [
        "prompt = \"givee me 10 animal name.\"\n",
        "\n",
        "response = gemini_model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2935.89ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.16ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 734.91ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1139.47ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1139.91ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 660.07ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 886.78ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 810.76ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 5791.58ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 582.90ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 886.86ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 709.15ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 683.03ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3465.57ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 4097.14ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 684.67ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.51ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1114.42ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 760.35ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1189.82ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 634.23ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 583.13ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.12ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Elephant\n",
            "2. Lion\n",
            "3. Tiger\n",
            "4. Giraffe\n",
            "5. Dolphin\n",
            "6. Penguin\n",
            "7. Monkey\n",
            "8. Snake\n",
            "9. Eagle\n",
            "10. Shark\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genereting text"
      ],
      "metadata": {
        "id": "ch33weLhNBgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code(prompt):\n",
        "    response = gemini_model.generate_content(prompt)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "_3nfHOQIKIlM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= \"once apon a time\"\n",
        "generated_text = generate_code(prompt)\n",
        "print(prompt , generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "4wdNsAhCLpTX",
        "outputId": "26242569-851a-40c4-ecc5-23f8b793ed65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "once apon a time Once upon a time... what happened next?  Tell me the rest of the story!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROGIaq1XL_ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customizing the output"
      ],
      "metadata": {
        "id": "sRlJYK3KNJi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "def generate_code(prompt,max_token):\n",
        "    response = gemini_model.generate_content(\n",
        "        prompt,\n",
        "        generation_config=genai.GenerationConfig(\n",
        "            temperature=0.2,\n",
        "            max_output_tokens=max_token\n",
        "        )\n",
        "    )\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "7NNQLP5zNOwM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = generate_code(prompt,100)\n",
        "print(prompt , generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gkf6Ig6rONXR",
        "outputId": "fd670d7c-74e9-49d8-a1e5-e0d50975203c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1696.62ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 987.59ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1695.07ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 633.54ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1619.39ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 583.16ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 759.67ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 760.13ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 709.92ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "once apon a time Once upon a time...  (What happens next?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "abJimA4jOVmM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIUcPGuAO4-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}